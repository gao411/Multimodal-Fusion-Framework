(1) Using a ResNet network to extract spatial-spectral-texture visual features from remote sensing imagery, socioeconomic features from POI data, and terrain attribute features from DEM data. Additionally, an Auxiliary Weighting Layer (AWL) was designed to which adaptively adjusts the contribution of different auxiliary features and evaluates the relative importance of different auxiliary data channels for the identification of the current functional zone; (2) Utilizing a dual-branch attention module (DBAM) to dynamically adapt to the contribution differences between remote sensing features and auxiliary features in different scenarios, overcoming traditional multi-source data fusion methods, enhancing the modeling of deep interaction mechanisms between cross-modal features; (3) Through the two submodules of multiscale feature extraction (Multiscale Feature Module, MFM) and modality interaction (Modality Interaction, MI) in the multimodal feature fusion module (Multiscale Feature Fusion Module, MFFM), integrates deep separable convolutions and Transformer encoders to enhance the modeling of deep interaction mechanisms between cross-modal features, enhancing the model's representational capability and classification stability for urban areas with high functional mixing and complex scenes; (4) Generate a distribution map of urban functional zones.
